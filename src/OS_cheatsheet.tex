\documentclass[8pt]{innovativeinnovation-cheatsheet}

% \cheatsheettitle{Example Cheat Sheet}

\begin{document}

\begin{multicols*}{3}

\cheatsheettitle{Virtualization}

\cheatsheetsection{Processes}

\textbf{Program:} A passive collection of instructions

\textbf{Process:} The abstraction provided by the OS of a running program

\textbf{Machine State:} What a program can read and change when it is running (registers, address spaces, open files, etc.)

\textbf{Process Control Block (PCB):} A data structure that contains the state of a process.

\textbf{Creation of A Process by OS:}
\begin{itemize}
      \item Load data from disk to memory
      \item Allocate space for the run-time stack and initialize the stack with arguments (i.e. fill in the parameters for argc and argv)
      \item Allocate memory for program's heap. Initially small, but OS may grow the heap as needed.
      \item Setup initial file descriptors (stdin, stdout, stderr).
      \item Transfer control of the CPU to the newly-created process (i.e. $\operatorname{main}()$ ).
\end{itemize}

\textbf{Context Switch:} the CPU stops running one process (or thread) and starts running another
\begin{itemize}
      \item Process A executes
      \item Hardware: generates timer interrupt, save \texttt{regs(A)} to kernel stack, move to kernel mode and jump to trap handler
      \item OS: Handle the trap, call \texttt{switch} routine, save \texttt{regs(A)} $\rightarrow$ \texttt{proc\_t(A)}, restore \texttt{regs(B)} $\leftarrow$ \texttt{proc\_t(B)}, switch to \texttt{k-stack(B)}, return-from-trap (into B)
      \item Hardware: restore \texttt{regs(B)} from kernel stack, move to user mode and jump to process B
      \item Process B executes.
\end{itemize}

\cheatsheetsection{CPU Scheduling}

\textbf{Running Time Metrics:}
\begin{itemize}
      \item \( T_{\text{turnaround}} = T_{\text{completion}} - T_{\text{arrival}}\)
      \item \( T_{\text{response}} = T_{\text{first run}} - T_{\text{arrival}}\)
\end{itemize}

\textbf{FIFO/FCFS}: First Come First Served, nonpreemptive

\textbf{SJF}: Shortest Job First, nonpreemptive

\textbf{STCF}: Shortest Time to Completion First, preemptive. Always run job that will complete the quickest

\textbf{MLFQ}: Multi-Level Feedback Queue, preemptive
\begin{enumerate}
      \item If Priority $(A)>$ Priority $(B)$ then A runs
      \item If Priority $(A)==$ Priority $(B)$ then A\&B run in RR
      \item Processes start at top priority
      \item Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced
      \item After some time period S, move all the jobs in the system to the topmost queue.
\end{enumerate}

\textbf{Lottery Scheduler:} Randomly selects the next process to run based on ticket probabilities, giving each process CPU time proportional to its number of tickets.
\begin{itemize}
      \item Ticket Currency: allows a user to allocate tickets among their running processes.
      \item Ticket Transfer: allows a process to temporarily hand off its tickets to another Process.
      \item Ticket Inflation: trusted processes can boost tickets to indicate its need for more CPU time.
\end{itemize}

\textbf{Unfairness Metric:} \( U = \frac{T(_{\text{process1 completion}})}{T(_{\text{process2 completion}})} \)

\textbf{Stride Scheduler}
\begin{itemize}
      \item Each process is assigned a stride, which is the inverse proportion to the number of tickets the process has. 
      \item Every time a process runs, its pass value is incremented by its stride.
      \item Scheduler selects the process with the smallest pass value.
\end{itemize}

\textbf{The Linux Completely Fair Scheduler (CFS):}
\begin{itemize}
      \item Divide a time length evenly among \( n \) processes. 
      \item Each process has a \texttt{vruntime} and a \texttt{nice} value.
      \item The process with the smallest \texttt{vruntime} is selected to run.
      \item Update \texttt{vruntime} of the running process by \[
            \texttt{vruntime}_i += \frac{\texttt{weight}_{0}}{\texttt{weight}_{\texttt{nice}_i}} \times \texttt{runtime}_i
      \]
      \item Ready jobs' \texttt{vruntime} are kept in a red-black tree.
      \item When jobs wake up, their \texttt{vruntime} is set to the minimum value in the tree.
      
\end{itemize}

\cheatsheetsection{Virtualiziang Memory}

\textbf{Transparency:} Process is unaware of sharing

\textbf{Static Allocation:} Randomlyewrites each program as it is loaded and placed in memory
\begin{itemize}
      \item No Protection
      \item Cannot move addresses space after it has been placed.
\end{itemize}

\textbf{Dynamic Allocation:} Allocates memory at run-time
\begin{itemize}
      \item Requires hardware support (Memory Management Unit)
      \item MMU dynamically changes process address at every memory reference
\end{itemize}

\textbf{Sparse Allocation:} Allocates memory in chunks, only allocate physical memory when needed.

\textbf{Base+Bounds:}
\begin{itemize}
      \item MMU compares logical address to bounds register.
      \item If logical address is out of bounds, raise an error.
      \item Otherwise, add base register to logical address to get physical address.
      \item OS sets registers when loading process.
      \item Process can be moved by updating its base register.
\end{itemize}

\textbf{Running Process with Base+Bounds:}
\begin{itemize}
      \item OS: allocate memory in process table, alloc memory for process, set base and bounds registers, then return from trap.
      \item Hardware: Restore registers, move to user mode, jump to process's \textbf{PC} (stores the next instruction address).
      \item Process A: fetch instruction
      \item Hardware: translate VA, perform fetch.
      \item Process A: execute instruction.
      \item Hardware: if explicit load/store, ensure address is legal and translate the VA.
\end{itemize}

\textbf{Segmentation:} Divide the address space into segments (Code, Stack, Heap), each segment has separate base+bounds registers and grows independently.
\begin{itemize}
      \item Explicit Approach: top bits of address select the segment, remaining are the offset.
      \item Implicit Approach: entire logical address is the offset, the corresponding segment is determined by how logical address is formed:
      \begin{itemize}
            \item Formed from PC (Program Counter): code segment.
            \item Formed from SP (Stack Pointer): stack segment.
            \item Anything else: heap segment.
      \end{itemize}
\end{itemize}

\begin{center}
\begin{tabular}{ccccc} 
      Segment & Base & Size & GrowsPositive? & Protection \\
      \hline 
      00 & 32 K & 2 K & 1 & R-X \\
      01 & 34 K & 3 K & 1 & R-W \\
      11 & 28 K & 2 K & 0 & R-W
\end{tabular}
\captionof{table}{Segment Register}
\end{center}

\cheatsheetsection{Paging} Divide virtual and physical memory into fixed-size pages Map virtual pages to physical pages with a page table

% \textbf{Terminologies:}
% \begin{itemize}
%       \item \textbf{VPN:} Virtual Page Number
%       \item \textbf{PFN:} Physical frame Number
%       \item \textbf{PTE:} Page Table Entry
%       \item \textbf{PDE:} Page Directory Entry
%       \item \textbf{TLB:} Translation Lookaside Buffer
% \end{itemize}

\textbf{TLB Contents}
\begin{itemize}
      \item \textbf{VPN:} used for lookup
      \item \textbf{PFN:} change the Virtual address VPN to PFN
      \item \textbf{G:} global bit (shared by all processes, don't check ASID)
      \item \textbf{ASID:} Address Space Identifier (which process's Page Table)
      \item \textbf{D:} dirty bit (changed when page has been written to)
      \item \textbf{V:} valid bit (valid translation present in entry)
\end{itemize}

% \textbf{Virtual Memory Mechanisms}
% First, hardware checks TLB for virtual address
% \begin{itemize}
%       \item If TLB hit, address translation done; page in physical memory
% \end{itemize}

% Else
% \begin{itemize}
%       \item Hardware or OS checks page table in memory
%       \item If PTE designates present, page in physical memory
% \end{itemize}

% Else
% \begin{itemize}
%       \item Trap into OS:
%       \item OS selects victim page in memory to replace
%       \item Writes victim page out to disk if modified (dirty bit is set)
%       \item OS reads referenced page from disk into memory
%       \item Page Table is updated, present bit is set
% - Process continues execution
% \end{itemize}

\textbf{Sapping Policy:}
\begin{itemize}
      \item \textbf{OPT:} Evict the page that will not be used for the longest time.
      \item \textbf{LRU:} Evict the page that has not been used for the longest time.
      \item \textbf{Random:} Randomly select a page to replace.
\end{itemize}

\textbf{Clock Algorithm:} Approximating LRU
\begin{itemize}
      \item Add use bit to PTE, whenever page is referenced, bit set to 1
      \item Imagine all the pages of the system arranged in a circular list
      \item A clock hand points to some particular page, P
      \item When replacement needs to happen, OS checks use bit of page P
      \item if 1 , (not good candidate) set use bit to 0 and advance P , keep looking
      \item if 0 , (good candidate) replace this page
\end{itemize}

\textbf{2-level Multi-level Paging Example:}
\begin{lstlisting}
      VA = 0x0214  (15 bits -> 5|5|5)
      +-------------+------------+----------+
      |DirIdx=0x00  |PTIdx=0x10  |Off=0x14 |
      +-------------+------------+----------+
             |
PDBR=13  -->  Physical Page #13 (Page Directory)
             |  Read byte 0 = PDE=0x83 
             v  (V=1, Page Table PFN=0x03)
          Physical Page #3 (Page Table)
             |  Read byte 16 = PTE=0x8E 
             v  (V=1, Data PFN=0x0E)
          Physical Page #14 (Data Page)
             |  Offset 0x14
             v
    Physical Address = (0x0E<<5) | 0x14 = 0x1D4
\end{lstlisting}

\textbf{VAX/VMS Virtual Memory Layout:}
\begin{itemize}
      \item Page 0 invalid
      \item Segmentation: P0, P1, S
      \begin{itemize}
            \item P0, P1: User segments
            \item S: System segments(Kernel)
      \end{itemize}
      \item Context Switch changes P0 \& P1 PT Registers
\end{itemize}

\textbf{Segmented FIFO}
\begin{itemize}
      \item RSS (Referenced Set Size): the maximum number of pages in memory for each process
      \item FIFO: first-in pages are moved to two \textbf{global} second-chance lists before actual eviction:
      \begin{itemize}
            \item Clean-Page Free List
            \item Dirty-Page List
      \end{itemize}
      \item If another process needs free page, take first page off clean list
      \item If original process needs page before actual eviction, reclaims it from list.
      \item As the global list grow, it performs similar to LRU.
      \item Uses Clustering of pages from dirty list to write to disk.
\end{itemize}

\textbf{Lazy Optmization: Demand Zeroing}: To prevent process read sensitive data from previous process, the OS first mark PTE invalid. Only on page fault (the process trying to use the page), the OS will zero the page.

\textbf{Copy-On-Write:} Share physical page across different processes. If one is writing, then copy the page and write to the new page.

\textbf{ASLR: Address Space Layout Randomization}: Randomize the address space layout of the process to avoid buffer overflow attacks.

\vfill

% \cheatsheetfooter{Innovative Innovation}{https://github.com/innovativeinnovation}

\newpage

\cheatsheettitle{Concurrency}

\cheatsheetsection{Threads and Locks}

\textbf{Threads:} Multiple threads of a process share:
\begin{itemize}
      \item Process ID (PID)
      \item Address Space: Code and Heap
      \item Open file descriptors
      \item Current working directory
      \item User and group IDs
\end{itemize}
Each thread has its own:
\begin{itemize}
      \item Stack for local variables and return addresses
      \item Set of registers, including program counter and stack pointer
      \item Thread ID (TID)
\end{itemize}

\textbf{Atomic Hardware Operation:}

For x86 systems:
\begin{itemize}
      \item \texttt{xchg(dst, src)}: exchanges the value of \texttt{dst} with \texttt{src}. Returns the original value of \texttt{dst}.
      \item \texttt{CompareAndSwap(dst, expected, new)}: if the value of \texttt{dst} is equal to \texttt{expected}, exchanges the value of \texttt{dst} with \texttt{new}. Returns the original value of \texttt{dst}.
\end{itemize}
For ARM systems:
\begin{itemize}
      \item \texttt{LoadLinked(*ptr)}: loads \texttt{ptr} and monitors for changes.
      \item \texttt{StoreConditional(*ptr, value)}: if the value of \texttt{ptr} has not changed since the last \texttt{LoadLinked}, then stores the value of \texttt{value} to \texttt{ptr} and returns 1. Otherwise, returns 0.
\end{itemize}

% \textbf{Compare and Swap (CAS):}

% \begin{lstlisting}
% int CompareAndSwap(int *addr, int expected, int new) {
%       int actual = *addr;
%       if (actual == expected) {
%             *addr = new;
%       }
%       return actual;
% }
% \end{lstlisting}

\textbf{Lock Implementation:}

With Atomic Exchange (Xchg):
\begin{lstlisting}
typedef struct __lock_t {
    int flag;
} lock_t;
void init(lock_t *lock) {
    lock->flag = 0;
}
void lock(lock_t *lock) {
    while(Xchg(&lock->flag, 1) == 1) {
        // spin-wait (do nothing)
    }
}
void unlock(lock_t *lock) {
    lock->flag = 0;
}
\end{lstlisting}

With Compare and Swap (CAS):
\begin{lstlisting}
void lock(lock_t *lock) {
    while (CompareAndSwap(&lock->flag, 0, 1) != 0) {
        //spin
    }
}
\end{lstlisting}

\cheatsheetsection{Condition Variables and Semaphores}

\textbf{Condition Variables:}
\texttt{wait(\&c, \&m)}: Wait for condition c to be signaled. It assumes the mutex m is locked when called. The call releases the lock and puts the thread to sleep. 

After another thread calls \texttt{signal(\&c)}, the thread will wake up and re-acquire the lock.

\textbf{Meaning of Signal: }
\begin{itemize}
      \item Mesa Semantics: When a thread signals a condition, the waiting thread is only marked as ready to run. 
      \item Hoare Semantics: When a thread signals a condition variable, it immediately transfers control to a waiting thread.
\end{itemize}
\begin{lstlisting}
//Mesa Semantics
pthread_mutex_lock(&mutex);
while (!condition) 
//The condition might still be false 
//when the thread wakes up
    pthread_cond_wait(&cond, &mutex);
\end{lstlisting}

\textbf{Semaphores:}
A semaphore is an object with an integer value that can be manipulated with two atomic routines:

\begin{lstlisting}
int sem_wait(sem_t *s) {
      // decrement the value of semaphore s by one
      // wait if value of semaphore s is negative
}
int sem_post(sem_t *s) {
      // increment the value of semaphore s by one
      // if there are threads waiting, wake one
}
\end{lstlisting}
Zemaphore implementation:
\begin{lstlisting}
typedef struct __Zem_t {
      int value;
      pthread_cond_t cond;
      pthread_mutex_t lock;
} Zem_t;

void Zem_init(Zem_t *s, int value) {
      s->value = value;
      Cond_init(&s->cond);
      Mutex_init(&s->lock);
}

void Zem_wait(Zem_t *s) {
    Mutex_lock(&s->lock);
    while (s->value <= 0)
        Cond_wait(&s->cond, &s->lock);
    s->value--;
    Mutex_unlock(&s->lock);
}

void Zem_post(Zem_t *s) {
    Mutex_lock(&s->lock);
    s->value++;
    Cond_signal(&s->cond);
    Mutex_unlock(&s->lock);
}

\end{lstlisting}

\textbf{Binary Semaphore:} A semaphore that can only be 0 or 1.
\begin{itemize}
      \item \texttt{sem\_wait}: If value = 1, set it to 0 and proceed. If value = 0, block until it becomes 1.
      \item \texttt{sem\_post}: If threads are waiting, wake one of them (value stays 0). Otherwise, set value = 1.
\end{itemize}

\textbf{Producer/Consumer Using Semaphores:}
\begin{lstlisting}
sem_t empty, full, mutex;
void *producer(void *arg) {
      int i;
      for(i=0;i<loops;i++) {
            sem_wait(&empty);
            sem_wait(&mutex);
            put(i);
            sem_post(&mutex);
            sem_post(&full);
      }
}

void *consumer(void *arg) {
    int i=0;
    for(i=0;i<loops;i++) {
        sem_wait(&full);
        sem_wait(&mutex);
        int tmp = get();
        sem_post(&mutex);
        sem_post(&empty);
        printf("%d\n",tmp);
    }
}

int main(int argc, char *argv[]) {
    // ...
    sem_init(&empty, 0, MAX);
    sem_init(&full, 0, 0);
    sem_init(&mutex, 0, 1);
    // ...
}

\end{lstlisting}

\cheatsheetsection{Concurrency Problems} 

\textbf{Conditions for Deadlock:}
\begin{itemize}
      \item Mutual exclusion: Threads claim exclusive control of resources that they require.
      \item Hold and wait: Threads hold resources while waiting for other resources.
      \item No preemption: Resources cannot be forcibly removed from threads
      \item Circular wait: Circular chain of threads hold resources that other threads are waiting for.
\end{itemize}

\textbf{Prevention Technique: Violating No Preemption}
\begin{lstlisting}
top:
    pthread_mutex_lock(L1);
    if (pthread_mutex_trylock(L2) != 0) {
        pthread_mutex_unlock(L1);
        goto top;
    }
\end{lstlisting}
\textbf{Problem: LiveLock.} Two threads may repeatedly attempt to acquire locks held by each other and repeatedly fail.

% \
% \begin{lstlisting}
% top:
%     pthread_mutex_lock(L1);
%     if (pthread_mutex_trylock(L2) != 0) {
%         pthread_mutex_unlock(L1);
%         goto top;
%     }
% \end{lstlisting}

\end{multicols*}

\end{document}
